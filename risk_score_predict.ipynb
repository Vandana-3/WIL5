{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to create the data structure\n",
    "def data_structure(n):\n",
    "    np.random.seed(42)  # Seed for reproducibility\n",
    "\n",
    "    # Creating a DataFrame\n",
    "    data = {\n",
    "        'Entity ID': np.arange(1, n + 1),\n",
    "        'Number of Clients Served Annually': np.random.choice(['<200', '201-500', '>500'], n, p=[0.3, 0.4, 0.3]),\n",
    "        'Past Infraction History Type': np.random.choice(['None', 'Minor Infractions', 'Major Infractions'], n, p=[0.6, 0.3, 0.1]),\n",
    "        'Past Infraction History Timeline': np.random.choice(['None', 'Within past year', '1-3 years ago'], n, p=[0.6, 0.2, 0.2]),\n",
    "        'Public Complaints Last Quarter': np.random.choice(['None', 'Minor', 'Major'], n, p=[0.7, 0.2, 0.1]),\n",
    "        'Quarterly Public Sentiment Analysis': np.random.choice(['None', 'Flagged'], n, p=[0.8, 0.2]),\n",
    "        'Previous Inspection Results': np.random.choice(['Pass', 'Fail', 'None'], n, p=[0.5, 0.1, 0.4])\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Print first few rows for verification\n",
    "    # print(df.head())\n",
    "    return df\n",
    "\n",
    "# Function to calculate the risk score\n",
    "def calculate_risk_score(row):\n",
    "    score_map = {\n",
    "        'Number of Clients Served Annually': {'<200': 1, '201-500': 2, '>500': 3},\n",
    "        'Past Infraction History Type': {'None': 1, 'Minor Infractions': 2, 'Major Infractions': 3},\n",
    "        'Past Infraction History Timeline': {'None': 1, 'Within past year': 2, '1-3 years ago': 3},\n",
    "        'Public Complaints Last Quarter': {'None': 1, 'Minor': 2, 'Major': 3},\n",
    "        'Quarterly Public Sentiment Analysis': {'None': 1, 'Flagged': 2},\n",
    "        'Previous Inspection Results': {'Pass': 1, 'Fail': 2, 'None': 1}\n",
    "    }\n",
    "\n",
    "    # Sum the points for each category based on the row's values\n",
    "    risk_score = sum(score_map[category][row[category]] for category in score_map)\n",
    "    return risk_score\n",
    "\n",
    "# Function to return the DataFrame with risk scores\n",
    "def dummydf(n=5000):\n",
    "    # Generate the data structure\n",
    "    df = data_structure(n)\n",
    "\n",
    "    # Apply the function to each row in the DataFrame to create the risk_score column\n",
    "    df['Risk Score'] = df.apply(calculate_risk_score, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Generate the DataFrame\n",
    "df = dummydf()\n",
    "#print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n",
      "Precision: 0.97\n",
      "Recall: 0.97\n",
      "F1 Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Prepare the Data\n",
    "X = df.drop(columns=['Entity ID', 'Risk Score'])\n",
    "y = df['Risk Score']\n",
    "\n",
    "# Encode categorical features\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.01\n",
      "R2 Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Prepare the Data\n",
    "X = df.drop(columns=['Entity ID', 'Risk Score'])\n",
    "y = df['Risk Score']\n",
    "\n",
    "# Encode categorical features\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Regressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R2 Score: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['risk_model.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, 'risk_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 19:37:17.091 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/mahnaz/vscodeProjects/dataTalent/regulatory proj/venv/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-05-22 19:37:17.094 Session state does not function when running a script without `streamlit run`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.2.76:8502\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Streamlit App\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('risk_model.pkl')\n",
    "\n",
    "# Function to preprocess input data\n",
    "def preprocess_input(data, model):\n",
    "    data_encoded = pd.get_dummies(data)\n",
    "    return data_encoded.reindex(columns=model.feature_importances_.argsort(), fill_value=0)\n",
    "\n",
    "# Streamlit app\n",
    "st.title('Regulatory Risk Prediction Tool')\n",
    "\n",
    "# User inputs\n",
    "st.header('Enter Entity Details')\n",
    "entity_id = st.text_input('Entity ID')\n",
    "num_clients = st.selectbox('Number of Clients Served Annually', ['<200', '201-500', '>500'])\n",
    "past_infraction_type = st.selectbox('Past Infraction History Type', ['None', 'Minor Infractions', 'Major Infractions'])\n",
    "past_infraction_timeline = st.selectbox('Past Infraction History Timeline', ['None', 'Within past year', '1-3 years ago'])\n",
    "public_complaints = st.selectbox('Public Complaints Last Quarter', ['None', 'Minor', 'Major'])\n",
    "sentiment_analysis = st.selectbox('Quarterly Public Sentiment Analysis', ['None', 'Flagged'])\n",
    "inspection_results = st.selectbox('Previous Inspection Results', ['Pass', 'Fail', 'None'])\n",
    "\n",
    "# Create a dataframe for input\n",
    "input_data = pd.DataFrame({\n",
    "    'Number of Clients Served Annually': [num_clients],\n",
    "    'Past Infraction History Type': [past_infraction_type],\n",
    "    'Past Infraction History Timeline': [past_infraction_timeline],\n",
    "    'Public Complaints Last Quarter': [public_complaints],\n",
    "    'Quarterly Public Sentiment Analysis': [sentiment_analysis],\n",
    "    'Previous Inspection Results': [inspection_results]\n",
    "})\n",
    "\n",
    "# Preprocess the input data\n",
    "input_data_encoded = preprocess_input(input_data, model)\n",
    "\n",
    "# Predict risk score\n",
    "if st.button('Predict Risk Score'):\n",
    "    risk_score = model.predict(input_data_encoded)[0]\n",
    "    st.write(f'Predicted Risk Score: {risk_score}')\n",
    "\n",
    "# Data visualization section\n",
    "st.header('Data Visualization')\n",
    "\n",
    "# Placeholder for data visualization\n",
    "# You can add code here to visualize data using Plotly, Matplotlib, or other libraries\n",
    "\n",
    "!streamlit run app.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 11:00:42.149 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/mahnaz/vscodeProjects/dataTalent/regulatory proj/venv/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-05-21 11:00:42.151 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    " # Streamlit App with Data Visualization Dashboard\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import plotly.express as px\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('risk_model.pkl')\n",
    "\n",
    "# Function to preprocess input data\n",
    "def preprocess_input(data, model):\n",
    "    data_encoded = pd.get_dummies(data)\n",
    "    return data_encoded.reindex(columns=model.feature_importances_.argsort(), fill_value=0)\n",
    "\n",
    "# Streamlit app\n",
    "st.title('Regulatory Risk Prediction Tool and Dashboard')\n",
    "\n",
    "# Sidebar for navigation\n",
    "st.sidebar.title(\"Navigation\")\n",
    "page = st.sidebar.radio(\"Go to\", [\"Prediction\", \"Data Visualization\"])\n",
    "\n",
    "if page == \"Prediction\":\n",
    "    st.header('Enter Entity Details for Prediction')\n",
    "    entity_id = st.text_input('Entity ID')\n",
    "    num_clients = st.selectbox('Number of Clients Served Annually', ['<200', '201-500', '>500'])\n",
    "    past_infraction_type = st.selectbox('Past Infraction History Type', ['None', 'Minor Infractions', 'Major Infractions'])\n",
    "    past_infraction_timeline = st.selectbox('Past Infraction History Timeline', ['None', 'Within past year', '1-3 years ago'])\n",
    "    public_complaints = st.selectbox('Public Complaints Last Quarter', ['None', 'Minor', 'Major'])\n",
    "    sentiment_analysis = st.selectbox('Quarterly Public Sentiment Analysis', ['None', 'Flagged'])\n",
    "    inspection_results = st.selectbox('Previous Inspection Results', ['Pass', 'Fail', 'None'])\n",
    "\n",
    "    # Create a dataframe for input\n",
    "    input_data = pd.DataFrame({\n",
    "        'Number of Clients Served Annually': [num_clients],\n",
    "        'Past Infraction History Type': [past_infraction_type],\n",
    "        'Past Infraction History Timeline': [past_infraction_timeline],\n",
    "        'Public Complaints Last Quarter': [public_complaints],\n",
    "        'Quarterly Public Sentiment Analysis': [sentiment_analysis],\n",
    "        'Previous Inspection Results': [inspection_results]\n",
    "    })\n",
    "\n",
    "    # Preprocess the input data\n",
    "    input_data_encoded = preprocess_input(input_data, model)\n",
    "\n",
    "    # Predict risk score\n",
    "    if st.button('Predict Risk Score'):\n",
    "        risk_score = model.predict(input_data_encoded)[0]\n",
    "        st.write(f'Predicted Risk Score: {risk_score}')\n",
    "\n",
    "elif page == \"Data Visualization\":\n",
    "    st.header('Data Visualization Dashboard')\n",
    "\n",
    "    # Load the dataset\n",
    "    df = dummydf()\n",
    "\n",
    "    # Calculate proportions of risk levels\n",
    "    risk_levels = df['Risk Score'].apply(lambda x: 'Low' if x < 7 else 'Moderate' if x <= 12 else 'High')\n",
    "    df['Risk Level'] = risk_levels\n",
    "    risk_counts = df['Risk Level'].value_counts().reset_index()\n",
    "    risk_counts.columns = ['Risk Level', 'Count']\n",
    "\n",
    "    # Display risk level proportions\n",
    "    st.subheader('Proportion of Risk Levels')\n",
    "    fig = px.pie(risk_counts, names='Risk Level', values='Count', title='Proportion of Risk Levels')\n",
    "    st.plotly_chart(fig)\n",
    "\n",
    "    # Risk level distribution\n",
    "    st.subheader('Risk Level Distribution')\n",
    "    fig = px.histogram(df, x='Risk Score', nbins=10, title='Risk Score Distribution')\n",
    "    st.plotly_chart(fig)\n",
    "\n",
    "    # Drill-down capability\n",
    "    st.subheader('Drill-Down on Entities')\n",
    "    risk_level_filter = st.selectbox('Select Risk Level to View Details', options=['All', 'Low', 'Moderate', 'High'])\n",
    "\n",
    "    if risk_level_filter != 'All':\n",
    "        filtered_df = df[df['Risk Level'] == risk_level_filter]\n",
    "    else:\n",
    "        filtered_df = df\n",
    "\n",
    "    st.dataframe(filtered_df)\n",
    "\n",
    "    # Additional visualizations can be added here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Mar  8 2023, 04:44:36) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "803c49d367f9116f590884443539198eb205200c56925f9465876482fde41f79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
